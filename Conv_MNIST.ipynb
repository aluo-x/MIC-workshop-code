{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple Convolutional network for MNIST by aluo\n",
    "\n",
    "%matplotlib inline\n",
    "# Inline plotting\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# Import some stuff from future, or else the code doesn't work\n",
    "from IPython import display\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Use the tensorflow MNIST downloader\n",
    "\n",
    "import tensorflow as tf\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    train_phase = tf.placeholder(tf.bool)\n",
    "    # The phase can be either training (network is learning) or inference (network is being used)\n",
    "    # So the train_phase is either true or false\n",
    "    # This will affect the application of batchnorm layers (not used) and dropout layers\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    # Set a placeholder to take in input\n",
    "    # Shape of input is a flattened 28 x 28 image, so 784 values\n",
    "    \n",
    "    digit_img = tf.reshape(x[0], [28, 28])\n",
    "    \n",
    "    x_img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # Reshape it into batchsize x 28 x 28 x 1 (because black & white)\n",
    "    \n",
    "    l_conv1 = tf.layers.conv2d(x_img, filters=32, kernel_size=(5, 5), padding='SAME', activation=tf.nn.relu)\n",
    "    # First layer outputs 32 feature maps and applies relu\n",
    "    \n",
    "    l_conv2 = tf.layers.conv2d(l_conv1, filters=64, kernel_size=(5, 5), padding='SAME', activation=tf.nn.relu)\n",
    "    # Second layer is a outputs 64 feature maps and applies relu\n",
    "    \n",
    "    l_norm1 = tf.layers.batch_normalization(l_conv2, training=train_phase)\n",
    "    # Apply batch norm\n",
    "    \n",
    "    l_pool1 = tf.layers.max_pooling2d(l_norm1, pool_size=[2, 2], strides=2)\n",
    "    # Apply pooling, reduces images size by factor 2 on each side, now is 14 x 14 x 64\n",
    "    \n",
    "    l_conv3 = tf.layers.conv2d(l_pool1, filters=32, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)\n",
    "    # Third layer is a outputs 32 feature maps and applies relu\n",
    "    \n",
    "    l_conv4 = tf.layers.conv2d(l_conv3, filters=16, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)\n",
    "    # Fourth layer is a outputs 16 feature maps and applies relu\n",
    "    \n",
    "    l_pool2 = tf.layers.max_pooling2d(l_conv4, pool_size=[2, 2], strides=2)\n",
    "    # Pool again, now is 7 x 7 x 16\n",
    "    \n",
    "    l_flat1 = tf.reshape(l_pool2, [-1, 7 * 7 * 16])\n",
    "    # Flatten the output of the previous layer\n",
    "    \n",
    "    l_dense1 = tf.layers.dense(l_flat1, units=512, activation=tf.nn.relu)\n",
    "    # Dense layer with 512 neurons\n",
    "    \n",
    "    l_dropout1 = tf.layers.dropout(inputs=l_dense1, rate=0.25, training=train_phase)\n",
    "    # Dropout 25%\n",
    "    \n",
    "    y_output = tf.layers.dense(l_dense1, units=10, activation=tf.nn.relu)\n",
    "    # Finally, make sure the output layer has 10 neurons (corresponding to the numbers from 0...9)\n",
    "    \n",
    "    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "    # Import data, set the labels to be a one-hot encoding\n",
    "    # So an image that represents 2\n",
    "    # Will have a label that is [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    # Remember 0 is the first digit!\n",
    "    \n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    # We define a place to input the label into the graph\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_output))\n",
    "    # Define a loss using cross-entropy \n",
    "    # Basically measures how different is the predicted label is from the actual label\n",
    "    # Take a mean across all 10 digits, could potentially also use a sum\n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    # Ported over from conv example\n",
    "    # Update Ops are required for batch_norm to work (moving average for batch mean & std)\n",
    "    \n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "        # Choose how we want to optimize (Adam is usually a good choice)\n",
    "        # And choose the loss that we want to minimize\n",
    "\n",
    "    y_output_digit = tf.argmax(y_output, 1)\n",
    "    y_digit = tf.argmax(y_, 1)\n",
    "    correct_prediction = tf.equal(y_output_digit, y_digit)\n",
    "    # Take the maximum probability as the predicted digits\n",
    "    # For example, if the network predicts [0.1, 0.8, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    # Then we say that the network predicts the image represents a 1\n",
    "    # We then compare this to y_ (the actual digit)\n",
    "    # If they are the same, we count it as a correct prediction\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # The accuracy is simply the correction predictions as a ratio of total predictions (batch size)\n",
    "    step_holder = []\n",
    "    accuracy_holder = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # Initialize the weights, offsets etc.\n",
    "        \n",
    "        for i in range(20000):\n",
    "            batch = mnist.train.next_batch(32)\n",
    "            # Get 32 images\n",
    "            \n",
    "            train_step.run(feed_dict={x: batch[0], y_: batch[1], train_phase: True})\n",
    "            # Run a round of optimizations \n",
    "            \n",
    "            if i % 15 == 0:\n",
    "                # Every 15 batches, we check on the accuracy\n",
    "                step_holder.append(i)\n",
    "                # Keep track of the steps\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], train_phase: False})\n",
    "                # Calculate the training_accuracy for the current batch\n",
    "                \n",
    "                accuracy_holder.append(train_accuracy)\n",
    "                # Keep track of the current accuracy\n",
    "                \n",
    "                display.clear_output(wait=True)\n",
    "                print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(digit_img.eval(feed_dict={x:batch[0]}))\n",
    "                plt.title(\"Predicted digit: {}\".format(y_output_digit.eval(feed_dict={x:batch[0],train_phase: False})[0]))\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot(step_holder, accuracy_holder)\n",
    "                plt.title(\"Accuracy vs training batches\")\n",
    "                # Plotting stuff\n",
    "                \n",
    "                display.display(plt.gcf())\n",
    "                plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data', help='Directory for storing input data')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
